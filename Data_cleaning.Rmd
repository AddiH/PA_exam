---
title: "Data_cleaning"
author: "Astrid Elmann"
date: "1/20/2022"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, readbulk)
```

```{r, message = FALSE}
# load data
d <- read_bulk(
  directory = 'logfiles',
  fun = read_csv
  )
```

```{r}
glimpse(d)
```


### Fix input mistake
```{r}
d <- d %>% 
  mutate(
    age = ifelse(age == "Tysk", "80", age))
```


### Check that no ID's are aciddentially identical
```{r}
# Check that these two dfs have the same number of rows
ID <- d %>% 
  group_by(experiment_ID) %>% 
  count(experiment_ID)

files <- d %>% 
  group_by(File) %>% 
  count(File)

# And this is double that (Might have one xtra "none", this will be removed later)
subjects <- d %>% 
  group_by(subject) %>% 
  count(subject)
```

### Check the r_len variable
```{r}
unique(d$r_len)
```

### Check the nationality variables
```{r}
unique(d$nationality)
```

### Remove slow trials
```{r}
d <- d %>% 
  # Trials where response was not within 1500 ms
  filter(key_press != "none")
```

### Remove colorblind, lefthanded (and ambidextrous) and people with poor vision
```{r}
d <- d %>% 
    filter(colorvision == "No" | colorvision == "Yes, but I can clearly tell the difference between blue and yellow") %>% 
    filter(vision == "Yes") %>% 
    filter(handedness == "Right")
```

### Add congruency column
```{r}
d <- d %>% 
  mutate(
    congruency = ifelse(trial_stim == "BR" | trial_stim == "YL", 'congruent', 'incongruent'),
    congruency = ifelse(trial_stim == 'BM' | trial_stim == "YM", 'neutral', congruency),
    congruency = as.factor(congruency),
  )
```

### Remove neutral trials
```{r}
d <- d %>% 
  filter(congruency != "neutral")
```

### Add accuracy column
```{r}
d <- d %>% 
  mutate(
    accuracy = ifelse(
      ((trial_stim == "BR" | trial_stim == "BM" | trial_stim == "BL") & key_press == "p") |
      ((trial_stim == "YR" | trial_stim == "YM" | trial_stim == "YL") & key_press == "w"), 
      'correct', 'error'),
    accuracy = as.factor(accuracy)
  )

# Getting no. of error trials
table(d$accuracy)["error"]
```
### Remove errors
```{r}
d <- d %>% 
  filter(accuracy != "error")
```


### Remove outliers
```{r}
# MAD method
lower_bound <- median(d$rt) - 3 * mad(d$rt, constant = 1)
lower_bound

upper_bound <- median(d$rt) + 3 * mad(d$rt, constant = 1)
upper_bound

# Just for fun
# Old, outdated +-3SD outlier method
upper <- mean(d$rt) + 3 * (sd(d$rt))
lower <- mean(d$rt) - 3 * (sd(d$rt))

```

```{r}
# Just for fun
# Visualizing which trials will be cut with each method
ggplot(d, aes(x = rt)) +
  geom_histogram(binwidth=.01) +
  geom_vline(xintercept = lower_bound) +
  geom_vline(xintercept = upper_bound) +
  geom_vline(xintercept = lower, colour="green") +
  geom_vline(xintercept = upper, colour="green")
```

```{r}
# See the outliers
outliers <- d %>% 
  filter(rt >= upper_bound | rt <= lower_bound) 

# Count outliers for each participant
outliers %>% 
  group_by(subject) %>% 
  summarise(N = n())

# As two participants have more than 30% of trials becoming outliers, they will be removed.
d <- d %>% 
  filter(subject != 31698 & subject != 33282)

# Remove the outliers
d <- d %>% 
   filter(rt <= upper_bound) %>% 
   filter(rt >= lower_bound)
```


### Save the df
```{r}
write_csv(d, "clean_data.csv")
```

